import logging
import re
from typing import Dict, List, Any
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
from config import Config

logger = logging.getLogger(__name__)


class ContentDetector:
    def __init__(self):
        self.model_name = Config.LLM_DETECTION_MODEL
        self.threshold = Config.LLM_DETECTION_THRESHOLD
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        try:
            # Load pre-trained model for LLM detection
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()
            logger.info(f"Loaded LLM detection model: {self.model_name}")
        except Exception as e:
            logger.warning(f"Failed to load LLM detection model: {str(e)}")
            self.model = None
            self.tokenizer = None
    
    def detect_llm_content(self, text: str) -> Dict[str, Any]:
        """
        Detect if content is generated by LLMs using multiple methods
        """
        results = {
            'overall_llm_probability': 0.0,
            'is_likely_llm_generated': False,
            'confidence': 0.0,
            'analysis': {
                'model_prediction': None,
                'pattern_analysis': None,
                'statistical_analysis': None
            },
            'suspicious_phrases': [],
            'recommendations': []
        }
        
        try:
            # Method 1: Model-based detection
            if self.model and self.tokenizer:
                model_results = self._model_based_detection(text)
                results['analysis']['model_prediction'] = model_results
            
            # Method 2: Pattern-based detection
            pattern_results = self._pattern_based_detection(text)
            results['analysis']['pattern_analysis'] = pattern_results
            
            # Method 3: Statistical analysis
            stat_results = self._statistical_analysis(text)
            results['analysis']['statistical_analysis'] = stat_results
            
            # Combine all methods
            results = self._combine_detection_methods(results)
            
            # Generate recommendations
            results['recommendations'] = self._generate_recommendations(results)
            
        except Exception as e:
            logger.error(f"Error in LLM content detection: {str(e)}")
            results['error'] = str(e)
        
        return results
    
    def _model_based_detection(self, text: str) -> Dict[str, Any]:
        """Use pre-trained model to detect LLM-generated content"""
        try:
            # Tokenize text
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # Get prediction
            with torch.no_grad():
                outputs = self.model(**inputs)
                probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
                llm_probability = probabilities[0][1].item()  # Assuming class 1 is LLM-generated
            
            return {
                'llm_probability': llm_probability,
                'is_llm_generated': llm_probability > self.threshold,
                'confidence': abs(llm_probability - 0.5) * 2  # Distance from uncertain (0.5)
            }
            
        except Exception as e:
            logger.error(f"Model-based detection failed: {str(e)}")
            return {
                'llm_probability': 0.0,
                'is_llm_generated': False,
                'confidence': 0.0,
                'error': str(e)
            }
    
    def _pattern_based_detection(self, text: str) -> Dict[str, Any]:
        """Detect LLM patterns using rule-based approach"""
        suspicious_phrases = []
        llm_indicators = 0
        total_indicators = 0
        
        # Common LLM phrases and patterns
        llm_patterns = {
            'chatgpt_phrases': [
                r"as an ai",
                r"i'm an ai",
                r"as a language model",
                r"i don't have personal",
                r"i can't browse the internet",
                r"my knowledge cutoff",
                r"i was trained on",
                r"based on my training",
                r"i'm here to help",
                r"feel free to ask"
            ],
            'formal_transitions': [
                r"furthermore",
                r"moreover",
                r"in addition",
                r"consequently",
                r"therefore",
                r"thus",
                r"hence"
            ],
            'generic_conclusions': [
                r"in conclusion",
                r"to summarize",
                r"in summary",
                r"overall",
                r"ultimately"
            ],
            'balanced_language': [
                r"on one hand.*on the other hand",
                r"while.*however",
                r"although.*nevertheless"
            ]
        }
        
        text_lower = text.lower()
        
        for category, patterns in llm_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, text_lower)
                if matches:
                    suspicious_phrases.extend(matches)
                    if category == 'chatgpt_phrases':
                        llm_indicators += len(matches) * 3  # High weight
                    else:
                        llm_indicators += len(matches)
                total_indicators += len(patterns)
        
        # Check for overly perfect grammar and structure
        sentences = re.split(r'[.!?]+', text)
        if len(sentences) > 5:
            avg_sentence_length = np.mean([len(s.split()) for s in sentences if s.strip()])
            if 15 <= avg_sentence_length <= 25:  # Typical LLM range
                llm_indicators += 1
            total_indicators += 1
        
        # Calculate probability
        pattern_probability = min(llm_indicators / max(total_indicators, 1), 1.0)
        
        return {
            'pattern_probability': pattern_probability,
            'suspicious_phrases': suspicious_phrases,
            'is_llm_generated': pattern_probability > 0.3,
            'indicators_found': llm_indicators,
            'total_indicators': total_indicators
        }
    
    def _statistical_analysis(self, text: str) -> Dict[str, Any]:
        """Analyze statistical properties of text"""
        try:
            words = text.split()
            sentences = re.split(r'[.!?]+', text)
            sentences = [s.strip() for s in sentences if s.strip()]
            
            if not words or not sentences:
                return {
                    'statistical_probability': 0.0,
                    'is_llm_generated': False,
                    'metrics': {}
                }
            
            metrics = {
                'avg_word_length': np.mean([len(word) for word in words]),
                'avg_sentence_length': np.mean([len(s.split()) for s in sentences]),
                'vocabulary_diversity': len(set(words)) / len(words),
                'punctuation_ratio': sum(1 for char in text if char in '.,!?;:') / len(text),
                'uppercase_ratio': sum(1 for char in text if char.isupper()) / len(text),
                'sentence_count': len(sentences),
                'word_count': len(words)
            }
            
            # Score based on typical LLM characteristics
            llm_score = 0
            
            # LLMs tend to use consistent sentence lengths (15-25 words)
            if 15 <= metrics['avg_sentence_length'] <= 25:
                llm_score += 0.2
            
            # LLMs tend to have moderate vocabulary diversity
            if 0.4 <= metrics['vocabulary_diversity'] <= 0.7:
                llm_score += 0.15
            
            # LLMs use proper punctuation
            if 0.02 <= metrics['punctuation_ratio'] <= 0.08:
                llm_score += 0.1
            
            # LLMs tend to use moderate word lengths
            if 4.5 <= metrics['avg_word_length'] <= 6.5:
                llm_score += 0.1
            
            return {
                'statistical_probability': llm_score,
                'is_llm_generated': llm_score > 0.35,
                'metrics': metrics
            }
            
        except Exception as e:
            logger.error(f"Statistical analysis failed: {str(e)}")
            return {
                'statistical_probability': 0.0,
                'is_llm_generated': False,
                'metrics': {},
                'error': str(e)
            }
    
    def _combine_detection_methods(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Combine results from all detection methods"""
        probabilities = []
        weights = []
        
        # Model-based (highest weight if available)
        model_result = results['analysis']['model_prediction']
        if model_result and 'error' not in model_result:
            probabilities.append(model_result['llm_probability'])
            weights.append(0.6)
        
        # Pattern-based
        pattern_result = results['analysis']['pattern_analysis']
        if pattern_result:
            probabilities.append(pattern_result['pattern_probability'])
            weights.append(0.3)
            results['suspicious_phrases'] = pattern_result['suspicious_phrases']
        
        # Statistical
        stat_result = results['analysis']['statistical_analysis']
        if stat_result and 'error' not in stat_result:
            probabilities.append(stat_result['statistical_probability'])
            weights.append(0.1)
        
        # Calculate weighted average
        if probabilities and weights:
            total_weight = sum(weights)
            weighted_prob = sum(p * w for p, w in zip(probabilities, weights)) / total_weight
        else:
            weighted_prob = 0.0
        
        # Calculate confidence
        if len(probabilities) > 1:
            confidence = 1.0 - (np.std(probabilities) * 2)  # Higher std = lower confidence
            confidence = max(0.0, min(1.0, confidence))
        else:
            confidence = 0.5
        
        results['overall_llm_probability'] = weighted_prob
        results['is_likely_llm_generated'] = weighted_prob > 0.5
        results['confidence'] = confidence
        
        return results
    
    def _generate_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on detection results"""
        recommendations = []
        
        if results['is_likely_llm_generated']:
            recommendations.append("Content appears to be LLM-generated. Consider manual review.")
            
            if results['suspicious_phrases']:
                recommendations.append(f"Found {len(results['suspicious_phrases'])} suspicious phrases that are common in AI-generated text.")
            
            if results['confidence'] > 0.8:
                recommendations.append("High confidence in LLM detection. Strong evidence of AI generation.")
            elif results['confidence'] < 0.4:
                recommendations.append("Low confidence in detection. May require human review.")
        else:
            recommendations.append("Content appears to be human-generated.")
            
            if results['overall_llm_probability'] > 0.3:
                recommendations.append("Some LLM characteristics detected but within acceptable range.")
        
        return recommendations